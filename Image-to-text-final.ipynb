{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d9ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Text:\n",
      "ELECTRONICS &\n",
      "\n",
      "TELECOMMUN!\n",
      "\n",
      "\n",
      "Detected Text:\n",
      "exalt\n",
      "\n",
      "Staff Signature Principal sig\n",
      "\n",
      "\n",
      "Detected Text:\n",
      "eer NG. y\n",
      "torName | Mr/Mé/Dr. RTO Ku titane —\n",
      "\n",
      "he ~ List ee\n",
      "\n",
      "sheets: 10\", 12\"/ Dij oma, Semester I to till date\n",
      "\n",
      "Certificates (MOOCS like NPTEL. Coursera ac\n",
      "1 Certificates (Parakh, CISCO ete.\n",
      "Spoken Tutorial Certificates.\n",
      "\n",
      "Achievements, copyrights, paper publications\n",
      "\n",
      "Proof of Membership (IEEE, ISTE, CSI, etc,)\n",
      "\n",
      "Internship Certificates\n",
      "Score Cards (GATE, GRE, TOEFEL, etc.)\n",
      "\n",
      "Placement Offer Letter\n",
      "\n",
      "NA\n",
      "Entrepreneurship Details NA\n",
      "sxit Survey and other feedback S [\n",
      "\n",
      "lubmiscian Séatne\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Path to Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def detect_text(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use pytesseract to detect text from the grayscale image\n",
    "    detected_text = pytesseract.image_to_string(gray_image,lang='eng')\n",
    "\n",
    "    return detected_text\n",
    "\n",
    "def main():\n",
    "    # Open the default camera (usually the first camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture frame.\")\n",
    "            break\n",
    "\n",
    "        # Display the captured frame\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "\n",
    "        # Check for user input to close the app\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('p'):\n",
    "            # Detect text when 'p' is pressed\n",
    "            text = detect_text(frame)\n",
    "            print(\"Detected Text:\")\n",
    "            print(text)\n",
    "            \n",
    "\n",
    "    # Release the camera and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import pyttsx3\n",
    "\n",
    "# Path to Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Initialize the pyttsx3 engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def detect_text(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use pytesseract to detect text from the grayscale image\n",
    "    detected_text = pytesseract.image_to_string(gray_image, lang='eng')\n",
    "\n",
    "    return detected_text\n",
    "\n",
    "def convert_text_to_speech(text):\n",
    "    # Convert the text to speech\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def main():\n",
    "    # Open the default camera (usually the first camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture frame.\")\n",
    "            break\n",
    "\n",
    "        # Display the captured frame\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "\n",
    "        # Check for user input to close the app or detect text\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('p'):\n",
    "            # Detect text when 'p' is pressed\n",
    "            text = detect_text(frame)\n",
    "            print(\"Detected Text:\")\n",
    "            print(text)\n",
    "\n",
    "            # Convert detected text to speech\n",
    "            convert_text_to_speech(text)\n",
    "\n",
    "    # Release the camera and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69424394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db0639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
